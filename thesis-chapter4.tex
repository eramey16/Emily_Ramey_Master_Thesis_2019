\chapter{Experiments}

\section{Toy Model Simulator}
Our toy model problem is a very basic simulator that traces the path of gamma rays through an example detector. We do not take the detector material into account, nor do we allow for any types of interactions other than Compton scattering. This allows us to test code in a controlled environment, which is very useful in the development of our reconstruction algorithm and enables us to ensure our code is performing as we expect without the additional errors caused by outside factors. However, due to this simplicity, there will be physical effects present in the real world that we fail to account for in our simulator, such as background radiation, photon scatters in the detector support material, and various electronic effects, that will increase our overall error. We turn to the Geant 4 software, a much more accurate physics simulator, to minimize these errors.

\subsection{Photon simulation}
The simulator function takes as its parameters the number of photons to generate and the number of hits each photon should have in the detector (including the final absorption). For each photon, we pick an initial energy from a uniform distribution between 100 keV and 20 MeV. We simulate the gamma rays at normal incidence, meaning their initial direction is perpendicular to the layers of the detector (***make a figure?), and each photon is initially centered with respect to the first layer.

Once we have set up our photon, we simulate its interaction with the detector by generating a random set of scattering angles according to the input number of hits. The scattering angles are taken from a uniform distribution from -90 to +90 degrees. We do not simulate back-scatters ($\geq$ 90 degrees) since these are relatively unlikely in the real world. We can then calculate the energy deposit of each hit using formula \ref{eq:compton}, the initial energy, and each scattering angle we have generated.

After calculating the angles and energy deposits, we then must calculate the position of each hit in the detector. To do this, we use a constant scattering probability to figure out which layers the photon will hit. For each hit, we determine the final direction the photon will travel by rotating the scattering angle randomly (with a 360$\deg$ uniform distribution) about the initial photon trajectory. This keeps the scattering angle constant but allows us to vary the scattering direction randomly, which is closer to the true physical phenomenon. Once we have each hit's layer and direction, we can use vector addition to determine each hit's position.

- how data is processed and saved
    - data is saved as a list of Hit data types for each photon (x, y, z, E)
    - which go into a list of Event data type (Hits, numHits)
    - and a list of Result data types (first two hits, eta, error in eta)
    - we use the Hit values to reconstruct the events and the Result values to check our work

\subsection{Errors and noise}
After getting each hit's position and energy deposit, we must simulate some error to approximate the noise level of our detector. We do this using a Gaussian distribution with variable standard deviation, $\sigma_S$. For the position measurements the user inputs the standard deviation in millimeters. For the energy measurements, the standard deviation is a function of the energy:
\begin{equation}
\frac{\sigma_E}{E} = a*\frac{1}{E \; in \; keV}
\end{equation}
where $a$ is a factor input by the user. We expect based on previous tests of the detector material \cite{}*** that $\sigma_S$ will be about 1 mm and $a$ will be about 0.22.

Though the probability distributions we use to generate our scattering angles are not the correct ones for Compton scattering, our use of formula \ref{eq:compton} ensures that no interaction we generate would be truly impossible in nature. Our reconstruction algorithm only compares the expected vs. the true angles and does not take the scattering probability into account, so this simulator still provides a fairly good test of our performance in the absence of measurement error. The true distribution of scattering angles is determined by the Klein-Nishina formula and the interaction probability by the Thomson cross-section \cite{klein-nishina}, so in later iterations of this project it may be useful to incorporate these into our toy model, particularly if we choose to integrate some component of the true scattering probabilities in our reconstruction algorithm.

\subsection{Toy model code}
- pseudocode

\section{Geant 4 Simulator}
- How does it compare to other gamma-ray simulators? Are there others like it?
- 

\section{Hardware} - add more details\\
The hardware we use to test our algorithm is the Raspberry Pi 3, Model B+. It uses a 4-core ARM processor with a 1.4 GHz processing speed, and has 1 Gb of RAM. Due to its low number of cores and static execution, it is a slower processor than found in most laptops, but it is perfect for testing our software as it is low-power enough to be used as part of a space telescope. The ARM processor is commonly used for scientific applications, and, as NASA has recently commissioned a space processor based on the same architecture, the Raspberry Pi could be the closest hardware we have to what our program will actually be running on in space. We also ran some tests on a machine at Washington University, Cassini, with a more advanced processor for comparison.

\section{Performance Measures}
In order to evaluate the performance of our algorithm, we use two main performance measures - the number of photons processed per second, and the accuracy. We consider a reconstruction accurate if the first two hits of the reconstruction match the first two hits in the correct sequence, and sometimes call this measure the two-hit accuracy for clarity. We report this statistic as the number of accurate reconstructions over the number of reconstructions total. We also considered power consumption as a measure of performance, but as the power used by the Raspberry Pi is so small as to be negligible for our purposes, it is not studied in-depth.

\section{Variables tested}
There are many variables that have the potential to affect the algorithm's performance, and we want to specifically examine the trade-offs in reconstruction speed vs. accuracy. The variables we examine are as follows:

\begin{enumerate}
    \item Hits simulated - The number of hits we simulate per photon
    \item Hits used - The number of hits used to reconstruct a photon's trajectory. Once the specified number of hits is reached, the sequence with the lowest eta value is presumed to be the correct one.
    \item Single vs. double precision - As our program is written in C++, we have a choice of whether to use \texttt{float} values (single precision) or \texttt{double} values in our calculations.
    \item $\chi^2$ cutoff - The p-value we use for our cutoff $\chi^2$ values. Ex: a p-value of .1 would give us a 10\% probability of cutting off a good triple, whereas a p-value of .01 would give us a 1\% probability of doing so.
    \item $\eta'$-tolerance - The $\eta'$ tolerance is the amount above 1 or below 0 that we will allow for a calculated cos(energy angle). For example, if the $\eta'$-tolerance is 0.2, any sequences containing an $\eta'$ > 1.2 would be cut.
    \item Predicted spatial and energy noise - Our $\chi^2$ calculations rely on the predicted errors of our $\eta$ and $\eta$ values, so changing the predicted level of error will change the behavior of our algorithm.
    \item Simulated spatial and energy noise - We would like to investigate the interplay between the predicted noise and the simulated noise for both position and energy calculations
\end{enumerate}